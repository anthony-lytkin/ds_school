{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 9-10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVG5TsA/LBVlgER8JH8xh0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthony-lytkin/ds_school/blob/main/Homework9-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jex_L-suK-gr"
      },
      "source": [
        "**Ex. 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL0hV0HFLC-H"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def f(x):\n",
        "    return x[0] ** 2 + 5 * x[1] ** 2\n",
        "\n",
        "def grad_f(x):\n",
        "    return np.array([2 * x[0] + 10 * x[1]])\n",
        "\n",
        "def grad_descent_const_step(x = np.array([0, 0]), alpha = 0.001, epsilon = 0.05):\n",
        "\n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    check = 0\n",
        "\n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
        "\n",
        "        x = x - alpha * grad\n",
        "        grad = grad_f(x)\n",
        "        n += 1\n",
        "\n",
        "        if np.linalg.norm(grad) <= epsilon:\n",
        "            check += 1\n",
        "\n",
        "    print('Constant step gradient descent was done for {} step(s).'.format(n))\n",
        "    print('Point: ({}, {}).'. format(x[0], x[1]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZT9UfoTN-zU"
      },
      "source": [
        "x = grad_descent_const_step()\n",
        "x = grad_descent_const_step(alpha = 0.01, epsilon = 0.5)\n",
        "x = grad_descent_const_step(alpha = 0.1, epsilon = 0.5)\n",
        "x = grad_descent_const_step(x = np.array([1, 1]))\n",
        "x = grad_descent_const_step(x = np.array([1, 1]), alpha = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyRETG4UP3RO"
      },
      "source": [
        "def grad_descent_step_splitting(x = np.array([0, 0]), alpha = 1, epsilon = 0.05, ksi = 0.5, lambda_d = 0.35):\n",
        "    \n",
        "    grad = grad_f(x)\n",
        "    n = 0\n",
        "    n_alpha = 0\n",
        "    alpha_k = alpha\n",
        "    x_k0 = x\n",
        "    check = 0\n",
        "    \n",
        "    while np.linalg.norm(grad) > epsilon or check < 3:\n",
        "        \n",
        "        grad = grad_f(x_k0)\n",
        "        x_k1 = x_k0 - alpha_k*grad\n",
        "        \n",
        "        while f(x_k1) - f(x_k0) > - alpha_k * ksi * (np.linalg.norm(grad) ** 2):\n",
        "            \n",
        "            alpha_k *= lambda_d\n",
        "            x_k1 = x_k0 - alpha_k * grad\n",
        "            n_alpha+=1\n",
        "\n",
        "        x_k0 = x_k0 - alpha_k * grad\n",
        "        alpha_k = alpha\n",
        "        n += 1\n",
        "        \n",
        "        if (np.linalg.norm(grad) <= epsilon): \n",
        "            check +=1\n",
        "    \n",
        "    x = x_k0\n",
        "    \n",
        "    print('Splitting step gradient descent was done for {} step(s).'.format(n))\n",
        "    print('{} iteration(s) of step splitting was completed.'.format(n_alpha))\n",
        "    print('Point: ({}, {}).'.format(x[0], x[1]))\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ekTFgQQuIf"
      },
      "source": [
        "grad_descent_step_splitting()\n",
        "grad_descent_step_splitting(alpha = 0.01, epsilon = 0.05, ksi = 0.1, lambda_d = 0.05)\n",
        "grad_descent_step_splitting(x = np.array([1, 1]))\n",
        "grad_descent_step_splitting(x = np.array([1, 1]), alpha = 1, epsilon = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auXgobRxVYwt"
      },
      "source": [
        "**Ex. 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI_2X23UVcNn"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EseRfPgevyGO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSq5Hs7VbRI_"
      },
      "source": [
        "**Ex. 3**\n",
        "\n",
        "Неподготовленному человеку, очень сложно :) Иных источников в интернете нету, везде текст данной статьи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF81nqyOeIHx"
      },
      "source": [
        "**Ex. 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nG_iOoebmNa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from math import pi, cos\n",
        "\n",
        "def prob_density(x):\n",
        "\n",
        "    return 0 if x <= np.pi or x > 1.5 * np.pi else - np.cos(x)\n",
        "\n",
        "\n",
        "x = np.arange(0, 2 * np.pi, 0.01)\n",
        "\n",
        "plt.plot(x, np.array([prob_density(y) for y in x.tolist()]))\n",
        "plt.title('Probability Density')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('P(x)')\n",
        "plt.grid(True)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoLTEuUsp0Dw"
      },
      "source": [
        "Probability:\n",
        "\n",
        "$$\n",
        "\\int\\limits_\\pi^{\\frac{5}{4}\\pi}-\\cos x dx = -\\sin x \\bigg|_\\pi^{\\frac{5}{4}\\pi} = \\frac{\\sqrt{2}}{2} + 0 = \\frac{\\sqrt{2}}{2} \\approx 0.71\n",
        "$$\n",
        "\n",
        "Expected value:\n",
        "\n",
        "$$\n",
        "M\\left[X\\right] = \\int\\limits_{-\\infty}^{+\\infty}x \\cdot (-\\cos x) dx = -\\int\\limits_{-\\infty}^{+\\infty} x \\cos x dx = -\\int\\limits_{\\pi}^{\\frac{3}{2}\\pi} x \\cos x dx = -\\int\\limits_{\\pi}^{\\frac{3}{2}\\pi} x d(\\sin x) = -x \\sin x \\bigg|_{\\pi}^{\\frac{3}{2}\\pi} + \\int\\limits_{\\pi}^{\\frac{3}{2}\\pi} \\sin x dx\n",
        "$$\n",
        "\n",
        "$$\n",
        "M\\left[X\\right] = \\frac{3}{2}\\pi - \\cos x \\bigg|_{\\pi}^{\\frac{3}{2}\\pi} = \\frac{3}{2}\\pi - 1 \\approx 3.71\n",
        "$$\n",
        "\n",
        "Variance:\n",
        "\n",
        "$$\n",
        "D\\left[X\\right] = \\int\\limits_{-\\infty}^{+\\infty} x^2 \\cdot (-\\cos x) dx = \n",
        "-\\int\\limits_{-\\infty}^{+\\infty} x^2 \\cdot \\cos x dx = -\\int\\limits_{\\pi}^{\\frac{3}{2}\\pi} x^2 \\cdot \\cos x dx = - x^2 \\cdot \\sin x \\bigg|_{\\pi}^{\\frac{3}{2}\\pi} + 2\\int\\limits_{\\pi}^{\\frac{3}{2}\\pi}x \\sin x dx\n",
        "$$\n",
        "\n",
        "$$\n",
        "D\\left[X\\right] = \\frac{9}{4}\\pi^2 - 2x \\cos x \\bigg|_{\\pi}^{\\frac{3}{2}\\pi} + 2 \\int\\limits_{\\pi}^{\\frac{3}{2}\\pi} \\cos x dx = \\frac{9}{4}\\pi^2 + 2 \\left( \\pi - 1 \\right) = \\frac{9}{4}\\pi - 2\\pi - 2 \n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wrCLqAC9Gce"
      },
      "source": [
        "**Ex. 5**\n",
        "\n",
        "Distribution function:\n",
        "\n",
        "$$\n",
        "F(x) = \\left\\{\n",
        "\\begin{array}{1}\n",
        "0, & x \\leqslant 1 \\\\\n",
        "x - 1, & 1 < x \\leqslant 2 \\\\\n",
        "1 & x > 2\n",
        "\\end{array} \\right .\n",
        "$$\n",
        "\n",
        "1. Continuous Function:\n",
        "\n",
        "$$\n",
        "True\n",
        "$$\n",
        "\n",
        "2. Probability density\n",
        "\n",
        "$$\n",
        "F(x) = \\left\\{\n",
        "\\begin{array}{1}\n",
        "0, & x \\leqslant 1 \\\\\n",
        "1, & 1 < x < \\leqslant 2 \\\\\n",
        "0, & x > 2\n",
        "\\end{array} \\right .\n",
        "$$\n",
        "\n",
        "3. Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRQc_VQ5DERH"
      },
      "source": [
        "def distribution(x):\n",
        "    return 0 if x <= 1 else 1 if x > 2 else x - 1\n",
        "\n",
        "\n",
        "def density(x):\n",
        "    return 1 if x > 1 and x <= 2 else 0\n",
        "\n",
        "\n",
        "x = np.arange(0, 3, 0.01)\n",
        "\n",
        "ax = plt.subplot()\n",
        "ax.plot(x, np.array([distribution(y) for y in x.tolist()]), label = 'F(x)')\n",
        "ax.plot(x, np.array([density(y) for y in x.tolist()]), label = 'p(x)')\n",
        "ax.legend()\n",
        "plt.title('Distribution and Density')\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kszAjdZdIij5"
      },
      "source": [
        "**Ex. 6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQNrh5SYYULl"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "act_pstv = [1 for i in range(100)]\n",
        "act_ngtv = [0 for i in range(10000)]\n",
        "\n",
        "pred_pstv = [0 for i in range(10)] + [1 for i in range(90)]\n",
        "pred_ngtv = [1 for i in range(30)] + [0 for i in range(9970)]\n",
        "\n",
        "y_true = act_pstv + act_ngtv\n",
        "y_pred = pred_pstv + pred_ngtv\n",
        "\n",
        "precision = sum(pred_pstv) / (sum(pred_pstv) + sum(pred_ngtv))\n",
        "precision_sklrn = precision_score(y_true, y_pred, average = 'binary')\n",
        "\n",
        "recall = sum(pred_pstv) / (sum(pred_pstv) + (sum(act_pstv) - sum(pred_pstv)))\n",
        "recall_sclrn = recall_score(y_true, y_pred, average = 'binary')\n",
        "\n",
        "betta = 1\n",
        "fscore = (1 + betta ** 2) * precision * recall / ((betta ** 2) * precision + recall)\n",
        "fscore_sclrn = f1_score(y_true, y_pred, average = 'binary')\n",
        "\n",
        "print('Precision: {:.3}, {:.3}'.format(precision, precision_sklrn))\n",
        "print('Recall: {:.3}, {:.3}'.format(recall, recall_sclrn))\n",
        "print('F1 score: {:.3}, {:.3}'.format(fscore, fscore_sclrn))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}